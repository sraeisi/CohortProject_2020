{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "tRlSS3aKPBG7"
   },
   "source": [
    "## Task #2\n",
    "\n",
    "In the following task, we will train a Restricted Boltzmann Machine (RBM) on 100 Rydberg atoms data. We will compare the energy of our simulated system against the exact known energy. In order to do this, it is necessary to explore some parameters of the Boltzman network. The number of hidden nodes and samples is important in order to obtain good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "OuqJaaB5PBHE"
   },
   "source": [
    "Imports and loading in data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "mnOc0DF6bcw7"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import Rydberg_energy_calculator\n",
    "from RBM_helper import RBM\n",
    "\n",
    "training_data = torch.from_numpy(np.loadtxt(\"Rydberg_data.txt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TGUmhEowPBH4"
   },
   "source": [
    "The binary data in ```Rydberg\\_data.txt``` corresponds to 100 atoms. An exact resolution of a system via diagonalization requires around $2^N$ terms, which in this case is beyond any possible calulation. Nontheless, RBM allow us to heavily compress this problem, changing the exponentially growing complexity for a linear growing complexity. For recovering the wavefunction of a system with 100 atoms, we only require $100 + n_h + n_h \\times 100$ numbers, where $n_h$ is the number of hidden nodes.\n",
    "\n",
    "We will evaluate the energy during training and compare it to the exact energy. This can be done with ```Rydberg\\_energy\\_calculator.py```. We will arbitrarly select a learning criterion, i.e. a limit to cut our training with satisfactory results.\n",
    "We selected as learning criteria $\\vert E_{RBM} - E_{exact} \\vert \\leq 0.0002$, where $E_{exact} = -4.1203519096$.\n",
    "\n",
    "This problem relies heavily on the size of the sample we take from our data. The more samples we use the more complex is the network we need to generalize. We will first consider the entire dataset and find the minimum number of hidden nodes required to reach the learning criteria.\n",
    "Each iteration will change the number of hidden nodes, and will have at most 1000 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "id": "H6Y9DjdSb7JB",
    "outputId": "1521d95f-3a0c-4ef4-dc4a-45c69576b5b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact energy:  -4.1203519096\n",
      "\n",
      " The number of hidden units is:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/pytorch/aten/src/ATen/native/BinaryOps.cpp:81: UserWarning: Integer division of tensors using div or / is deprecated, and in a future release div will perform true division as in Python 3. Use true_divide or floor_divide (// in Python) instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100 . Energy from RBM samples: -4.120062240258802 . Error: 0.0002896693411980067\n",
      "Epoch: 200 . Energy from RBM samples: -4.119976002260587 . Error: 0.00037590733941339494\n",
      "Epoch: 300 . Energy from RBM samples: -4.120082717140181 . Error: 0.0002691924598190454\n",
      "Epoch: 400 . Energy from RBM samples: -4.120004489701917 . Error: 0.00034741989808306784\n",
      "Epoch: 500 . Energy from RBM samples: -4.120038590317868 . Error: 0.00031331928213251814\n",
      "Epoch: 600 . Energy from RBM samples: -4.120016504978766 . Error: 0.0003354046212340478\n",
      "Epoch: 700 . Energy from RBM samples: -4.120052344188419 . Error: 0.0002995654115807156\n",
      "Epoch: 800 . Energy from RBM samples: -4.120031126971855 . Error: 0.0003207826281448334\n",
      "Epoch: 900 . Energy from RBM samples: -4.120077148590775 . Error: 0.0002747610092255215\n",
      "Epoch: 1000 . Energy from RBM samples: -4.1201191562144714 . Error: 0.000232753385528639\n",
      "\n",
      " The number of hidden units is:  2\n",
      "Epoch: 100 . Energy from RBM samples: -4.119901615188974 . Error: 0.00045029441102606427\n",
      "Epoch: 200 . Energy from RBM samples: -4.12001080077413 . Error: 0.00034110882586979585\n",
      "Epoch: 300 . Energy from RBM samples: -4.120007100548132 . Error: 0.0003448090518682889\n",
      "Epoch: 400 . Energy from RBM samples: -4.120010617747241 . Error: 0.00034129185275943996\n",
      "Epoch: 500 . Energy from RBM samples: -4.120047846936224 . Error: 0.00030406266377625\n",
      "Epoch: 600 . Energy from RBM samples: -4.120022673662488 . Error: 0.00032923593751199576\n",
      "Epoch: 700 . Energy from RBM samples: -4.11993806577881 . Error: 0.00041384382118980767\n",
      "Epoch: 800 . Energy from RBM samples: -4.1201038421934655 . Error: 0.00024806740653460224\n",
      "Epoch: 900 . Energy from RBM samples: -4.120029423888304 . Error: 0.000322485711696352\n",
      "Epoch: 1000 . Energy from RBM samples: -4.120040076902718 . Error: 0.00031183269728174423\n",
      "\n",
      " The number of hidden units is:  3\n",
      "Epoch: 100 . Energy from RBM samples: -4.119937551803987 . Error: 0.00041435779601339817\n",
      "Epoch: 200 . Energy from RBM samples: -4.119941937267594 . Error: 0.0004099723324060278\n",
      "Epoch: 300 . Energy from RBM samples: -4.119923508856669 . Error: 0.00042840074333128086\n",
      "Epoch: 400 . Energy from RBM samples: -4.120017205786917 . Error: 0.0003347038130829816\n",
      "Epoch: 500 . Energy from RBM samples: -4.120028174162648 . Error: 0.0003237354373517576\n",
      "Epoch: 600 . Energy from RBM samples: -4.120159403947918 . Error: 0.00019250565208217552\n",
      "FINAL NUMBER OF HIDDEN UNITS: 3\n",
      "FINAL NUMBER OF EPOCHS: 600\n",
      "ERROR: 0.00019250565208217552\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "i = 0\n",
    "epochs = 1000\n",
    "num_samples = 20000 \n",
    "n_vis = training_data.shape[1]\n",
    "exact_energy = -4.1203519096\n",
    "print(\"Exact energy: \",exact_energy)\n",
    "\n",
    "while flag == 0 :\n",
    "    i = i + 1\n",
    "    n_hin = i\n",
    "    rbm = RBM(n_vis, n_hin)\n",
    "    print(\"\\n The number of hidden units is: \", n_hin)\n",
    "  \n",
    "    e = 0\n",
    "    while (e < epochs):\n",
    "        e = e + 1\n",
    "        rbm.train(training_data)   \n",
    "        if e % 100 == 0:\n",
    "            init_state = torch.zeros(num_samples, n_vis)\n",
    "            RBM_samples = rbm.draw_samples(1000, init_state)\n",
    "            energies = Rydberg_energy_calculator.energy(RBM_samples, rbm.wavefunction) \n",
    "            print(\"Epoch:\", e,\". Energy from RBM samples:\", energies.item(),\". Error:\", abs(exact_energy - energies.item()))\n",
    "            if (abs(exact_energy - energies.item()) < 0.0002):\n",
    "                print(\"FINAL NUMBER OF HIDDEN UNITS:\", n_hin)\n",
    "                print(\"FINAL NUMBER OF EPOCHS:\", e)\n",
    "                print(\"ERROR:\", abs(exact_energy - energies.item()))\n",
    "                e = epochs\n",
    "                flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QPgJEmjoPBIU"
   },
   "source": [
    "We will now double the number of hidden units (and hence the complexity of the network), but lowering the number of samples to find the minimum required number to achive the same ammount of precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "G4NEzI8CYllc",
    "outputId": "597a909b-fa0b-4097-b091-9ea88b52ffca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact energy:  -4.1203519096 . Hidden units: 6 .\n",
      "\n",
      "The number of samples is:  10\n",
      "Epoch: 100 . Energy from RBM samples: -4.114849608549276 . Error: 0.005502301050723801\n",
      "Epoch: 200 . Energy from RBM samples: -4.118903595039777 . Error: 0.0014483145602230962\n",
      "Epoch: 300 . Energy from RBM samples: -4.11916454590617 . Error: 0.0011873636938304344\n",
      "Epoch: 400 . Energy from RBM samples: -4.119307788753898 . Error: 0.001044120846102281\n",
      "Epoch: 500 . Energy from RBM samples: -4.1191645907336305 . Error: 0.00118731886636958\n",
      "Epoch: 600 . Energy from RBM samples: -4.121560546042896 . Error: 0.0012086364428958163\n",
      "Epoch: 700 . Energy from RBM samples: -4.119111079515618 . Error: 0.0012408300843818054\n",
      "Epoch: 800 . Energy from RBM samples: -4.118059725777168 . Error: 0.00229218382283225\n",
      "Epoch: 900 . Energy from RBM samples: -4.119417895696038 . Error: 0.0009340139039624162\n",
      "Epoch: 1000 . Energy from RBM samples: -4.117016605105741 . Error: 0.003335304494259006\n",
      "\n",
      "The number of samples is:  20\n",
      "Epoch: 100 . Energy from RBM samples: -4.120370450645092 . Error: 1.8541045092135278e-05\n",
      "NUMBER OF SAMPLES: 20\n",
      "FINAL NUMBER OF EPOCHS: 100\n",
      "ERROR: 1.8541045092135278e-05\n"
     ]
    }
   ],
   "source": [
    "flag = 0\n",
    "i = 0\n",
    "epochs = 1000\n",
    "n_hin = 3 * 2 # in the previous case it converged with 3 units\n",
    "n_vis = training_data.shape[1]\n",
    "exact_energy = -4.1203519096\n",
    "print(\"Exact energy: \",exact_energy,\". Hidden units:\",n_hin,\".\")\n",
    "\n",
    "while flag == 0 :\n",
    "  i = i + 1\n",
    "  num_samples = 10 * i\n",
    "  rbm = RBM(n_vis, n_hin)\n",
    "  print(\"\\nThe number of samples is: \", num_samples)\n",
    "  \n",
    "  e = 0\n",
    "  while (e < epochs):\n",
    "    e = e + 1\n",
    "    rbm.train(training_data)   \n",
    "    if e % 100 == 0:\n",
    "      init_state = torch.zeros(num_samples, n_vis)\n",
    "      RBM_samples = rbm.draw_samples(1000, init_state)\n",
    "      energies = Rydberg_energy_calculator.energy(RBM_samples, rbm.wavefunction) \n",
    "      print(\"Epoch:\", e,\". Energy from RBM samples:\", energies.item(),\". Error:\", abs(exact_energy - energies.item()))\n",
    "      if (abs(exact_energy - energies.item()) < 0.0002):\n",
    "        print(\"NUMBER OF SAMPLES:\", num_samples)\n",
    "        print(\"FINAL NUMBER OF EPOCHS:\", e)\n",
    "        print(\"ERROR:\", abs(exact_energy - energies.item()))\n",
    "        e = epochs\n",
    "        flag = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NfpJMedTPIHl"
   },
   "source": [
    "For a better precission with the whole data set, such as $\\vert E_{RBM} - E_{exact} \\vert \\leq 0.0001$, the required number of hidden nodes is extremly hard to find. Iteration leading up to 100 did not found any case, we even tried it with a greater number of hidden units without meeting the learning criteria. As the number of samples decreases, the complexity of the system necessary to meet the learning criteria gets lower.\n",
    "\n",
    "More information on these kind of systems with RBM can be found in the work [Integrating Neural Networks with a Quantum Simulator for State Reconstruction](https://arxiv.org/pdf/1904.08441.pdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Task2_final.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
